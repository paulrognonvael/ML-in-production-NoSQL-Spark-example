{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "#### First Name: Paul\n",
    "#### Last Name: Rognon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "spark = SparkSession.builder.appName(\"Twitter Analysis\")\\\n",
    ".getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter = spark.read.json(\"corona_tweet_new.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- favorite_count: long (nullable = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- in_reply_to_status_id: string (nullable = true)\n",
      " |-- in_reply_to_user_id_str: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- reply_count: long (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- user: struct (nullable = true)\n",
      " |    |-- contributors_enabled: boolean (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- default_profile: boolean (nullable = true)\n",
      " |    |-- default_profile_image: boolean (nullable = true)\n",
      " |    |-- description: string (nullable = true)\n",
      " |    |-- favourites_count: long (nullable = true)\n",
      " |    |-- follow_request_sent: string (nullable = true)\n",
      " |    |-- followers_count: long (nullable = true)\n",
      " |    |-- following: string (nullable = true)\n",
      " |    |-- friends_count: long (nullable = true)\n",
      " |    |-- geo_enabled: boolean (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- id_str: string (nullable = true)\n",
      " |    |-- is_translator: boolean (nullable = true)\n",
      " |    |-- lang: string (nullable = true)\n",
      " |    |-- listed_count: long (nullable = true)\n",
      " |    |-- location: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- notifications: string (nullable = true)\n",
      " |    |-- profile_background_color: string (nullable = true)\n",
      " |    |-- profile_background_image_url: string (nullable = true)\n",
      " |    |-- profile_background_image_url_https: string (nullable = true)\n",
      " |    |-- profile_background_tile: boolean (nullable = true)\n",
      " |    |-- profile_banner_url: string (nullable = true)\n",
      " |    |-- profile_image_url: string (nullable = true)\n",
      " |    |-- profile_image_url_https: string (nullable = true)\n",
      " |    |-- profile_link_color: string (nullable = true)\n",
      " |    |-- profile_sidebar_border_color: string (nullable = true)\n",
      " |    |-- profile_sidebar_fill_color: string (nullable = true)\n",
      " |    |-- profile_text_color: string (nullable = true)\n",
      " |    |-- profile_use_background_image: boolean (nullable = true)\n",
      " |    |-- protected: boolean (nullable = true)\n",
      " |    |-- screen_name: string (nullable = true)\n",
      " |    |-- statuses_count: long (nullable = true)\n",
      " |    |-- time_zone: string (nullable = true)\n",
      " |    |-- translator_type: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |    |-- utc_offset: string (nullable = true)\n",
      " |    |-- verified: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_twitter.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- favorite_count: long (nullable = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- in_reply_to_status_id: string (nullable = true)\n",
      " |-- in_reply_to_user_id_str: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- reply_count: long (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- user_id_str: string (nullable = true)\n",
      " |-- user_followers_count: long (nullable = true)\n",
      " |-- user_friends_count: long (nullable = true)\n",
      " |-- user_created_at: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col \n",
    "first_cols = df_twitter.columns[0:(len(df_twitter.columns)-1)]\n",
    "df_twitter = df_twitter.select(first_cols+[col(\"user.id_str\").alias(\"user_id_str\"),\n",
    "                                                col(\"user.followers_count\").alias(\"user_followers_count\"),\n",
    "                                                col(\"user.friends_count\").alias(\"user_friends_count\"),\n",
    "                                                col(\"user.created_at\").alias(\"user_created_at\")])\n",
    "df_twitter.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15894\n"
     ]
    }
   ],
   "source": [
    "# Print the total count of number of records in df_twitter(1 point)\n",
    "print(df_twitter.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------+\n",
      "|source                                                                              |\n",
      "+------------------------------------------------------------------------------------+\n",
      "|<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>             |\n",
      "|<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>|\n",
      "|<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>|\n",
      "|<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>|\n",
      "|<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>|\n",
      "|<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>             |\n",
      "|<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>                  |\n",
      "|<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>|\n",
      "|<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>|\n",
      "|<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>  |\n",
      "+------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_twitter.select(col(\"source\")).show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|   extracted_source|              source|\n",
      "+-------------------+--------------------+\n",
      "|    Twitter Web App|<a href=\"https://...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|    Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web Client|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "| Twitter for iPhone|<a href=\"http://t...|\n",
      "| Twitter for iPhone|<a href=\"http://t...|\n",
      "|    Twitter Web App|<a href=\"https://...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|    Twitter Web App|<a href=\"https://...|\n",
      "| Twitter for iPhone|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "| Twitter for iPhone|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "| Twitter for iPhone|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract the source label from source col by droping the anchor tab and save it as another col named extracted_source\n",
    "# for example <a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a> => Twitter Web App\n",
    "# you can use \"<a [^>]+>([^<]+)\" as regualr expresion and the group would be 1 for this regular expression.\n",
    "#(4 points)\n",
    "\n",
    "from pyspark.sql.functions import regexp_extract, col\n",
    "df_twitter = df_twitter.withColumn('extracted_source',\n",
    "                                    regexp_extract(df_twitter['source'],'<a [^>]+>([^<]+)',1))\n",
    "df_twitter.select(col('extracted_source'),col('source')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame into RDD\n",
    "rdd_twitter=df_twitter.rdd.map(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporay table in memory with name as twitter (1 point)\n",
    "df_twitter.createOrReplaceTempView(\"twitter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze Data\n",
    "\n",
    "#### You will be writing code to find the answer to the questions listed below using Just RDD, Using spark SQL \n",
    "\n",
    "- Analyze using RDD \n",
    "- Analyze using Dataframe without temp table \n",
    "- Analyze using spark.sql with temp table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Get total number of unique users (1 point for each type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14094"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD\n",
    "user_tweet = rdd_twitter.map(lambda s : (s[10], 1))\n",
    "user_tweet = user_tweet.reduceByKey(lambda a, b : a + b)\n",
    "user_tweet.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14094"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using DataFrame\n",
    "df_twitter.select(\"user_id_str\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|count(DISTINCT user_id_str)|\n",
      "+---------------------------+\n",
      "|                      14094|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table.\n",
    "spark.sql(\"SELECT COUNT (DISTINCT user_id_str) FROM twitter\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Get count of user who have more than 1 tweet in the data (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1016"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD\n",
    "user_tweet.filter(lambda s: s[1] > 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1016"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using DataFrame\n",
    "df_twitter_temp = df_twitter.groupby(\"user_id_str\").count()\n",
    "df_twitter_temp.filter(df_twitter_temp[\"count\"]>1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    1016|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table.\n",
    "spark.sql(\"SELECT user_id_str,COUNT(*) AS NB FROM twitter GROUP BY user_id_str\").createOrReplaceTempView(\"twitter_temp\")\n",
    "spark.sql(\"SELECT COUNT(*) FROM twitter_temp WHERE NB > 1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Get total number unique extracted_source (1 point each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD\n",
    "source_tweet = rdd_twitter.map(lambda s : (s[14], 1))\n",
    "source_tweet = source_tweet.reduceByKey(lambda a, b : a + b)\n",
    "source_tweet.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using DataFrame\n",
    "df_twitter.select(\"extracted_source\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table.\n",
    "spark.sql(\"SELECT DISTINCT extracted_source FROM twitter\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Get top 5 most used extracted_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Twitter for Android', 6262),\n",
       " ('Twitter for iPhone', 5698),\n",
       " ('Twitter Web App', 2878),\n",
       " ('Twitter for iPad', 428),\n",
       " ('Twitter Web Client', 136)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD (5 points)\n",
    "source_tweet.takeOrdered(5, lambda s: -1 * s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|   extracted_source|count|\n",
      "+-------------------+-----+\n",
      "|Twitter for Android| 6262|\n",
      "| Twitter for iPhone| 5698|\n",
      "|    Twitter Web App| 2878|\n",
      "|   Twitter for iPad|  428|\n",
      "| Twitter Web Client|  136|\n",
      "+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using DataFrame (2 points)\n",
    "df_twitter.groupBy(\"extracted_source\").count().sort(\"count\", ascending = False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+\n",
      "|   extracted_source|NB_2|\n",
      "+-------------------+----+\n",
      "|Twitter for Android|6262|\n",
      "| Twitter for iPhone|5698|\n",
      "|    Twitter Web App|2878|\n",
      "|   Twitter for iPad| 428|\n",
      "| Twitter Web Client| 136|\n",
      "+-------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table. (2 points)\n",
    "spark.sql(\"select extracted_source, COUNT (*) AS NB_2 FROM twitter GROUP BY extracted_source order by NB_2 desc\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Get count of distinct hastags used ( 5 point each) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1215"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD\n",
    "rdd_twitter.flatMap(lambda s : s[2]).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1215"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using DataFrame\n",
    "from pyspark.sql.functions import explode, flatten\n",
    "df_twitter.select(explode(df_twitter.hashtags)).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(DISTINCT col)|\n",
      "+-------------------+\n",
      "|               1215|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table.\n",
    "spark.sql(\"SELECT explode(hashtags) FROM twitter\").createOrReplaceTempView(\"hashtag_temp\")\n",
    "spark.sql(\"SELECT COUNT(DISTINCT col) FROM hashtag_temp\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Get top 5 hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('طبق_القدرات_للثانويه_ياريس', 385),\n",
       " ('Corona', 319),\n",
       " ('OilPrice', 251),\n",
       " ('COVID19', 125),\n",
       " ('corona', 123)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD (4 points)\n",
    "hash_dic = rdd_twitter.flatMap(lambda s : s[2]).countByValue()\n",
    "sorted(hash_dic.items(),reverse=True, key=lambda item: item[1])[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                 col|count|\n",
      "+--------------------+-----+\n",
      "|طبق_القدرات_للثان...|  385|\n",
      "|              Corona|  319|\n",
      "|            OilPrice|  251|\n",
      "|             COVID19|  125|\n",
      "|              corona|  123|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using DataFrame (2 points)\n",
    "from pyspark.sql.functions import explode\n",
    "df_twitter.select(explode(df_twitter.hashtags)).groupBy(\"col\").count().sort(col(\"count\").desc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|                 col|freq|\n",
      "+--------------------+----+\n",
      "|طبق_القدرات_للثان...| 385|\n",
      "|              Corona| 319|\n",
      "|            OilPrice| 251|\n",
      "|             COVID19| 125|\n",
      "|              corona| 123|\n",
      "+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table. (2 points)\n",
    "spark.sql(\"\"\"SELECT col, COUNT(col) AS freq \n",
    "    FROM hashtag_temp\n",
    "    GROUP BY col\n",
    "    ORDER BY freq DESC\n",
    "    LIMIT 5\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Get total number of tweets which are retweeted more than 100 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15753"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD\n",
    "rdd_twitter.filter(lambda s: s[8] > 100).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15753"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using DataFrame\n",
    "df_twitter.filter(df_twitter[\"retweet_count\"]>100).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   15753|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table.\n",
    "spark.sql(\"select COUNT (*) FROM twitter WHERE retweet_count > 100\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8 Get top 3 most retweeted tweets per country (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('USA',\n",
       "  [('1252331777806524416', 9994),\n",
       "   ('1252254239805579264', 9987),\n",
       "   ('1252335464750735362', 9982)]),\n",
       " ('Pakistan',\n",
       "  [('1252334264248606720', 9988),\n",
       "   ('1252251912084357121', 9975),\n",
       "   ('1252252126694309888', 9973)])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD\n",
    "country_retweet = rdd_twitter.map(lambda s : (s[6], (s[3],s[8])))\n",
    "# RDD with ids of three most retweeted and the number of retweets\n",
    "country_retweet=country_retweet.groupByKey().mapValues(lambda x: sorted(x,reverse=True, key=lambda x :x[1])[0:3])\n",
    "country_retweet.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------+----+\n",
      "|location|                 id|retweet_count|rank|\n",
      "+--------+-------------------+-------------+----+\n",
      "| Germany|1252334028092399622|         9999|   1|\n",
      "| Germany|1252330902325248000|         9997|   2|\n",
      "| Germany|1252252295510855682|         9990|   3|\n",
      "|   China|1252335780707684352|         9998|   1|\n",
      "|   China|1252253596516843520|         9993|   2|\n",
      "|   China|1252255562525560832|         9984|   3|\n",
      "|   India|1252332114948874240|         9988|   1|\n",
      "|   India|1252252336921206787|         9976|   2|\n",
      "|   India|1252254519116746754|         9973|   3|\n",
      "|   Chile|1252253612140490759|         9988|   1|\n",
      "|   Chile|1252334891951427585|         9984|   2|\n",
      "|   Chile|1252253710182481920|         9978|   3|\n",
      "|   Italy|1252252106750377996|         9994|   1|\n",
      "|   Italy|1252251206027816960|         9984|   2|\n",
      "|   Italy|1252330500670337024|         9971|   3|\n",
      "|   Spain|1252335445876367361|         9992|   1|\n",
      "|   Spain|1252334839094599681|         9981|   2|\n",
      "|   Spain|1252254696112300032|         9969|   3|\n",
      "|     USA|1252331777806524416|         9994|   1|\n",
      "|     USA|1252254239805579264|         9987|   2|\n",
      "+--------+-------------------+-------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank, col,row_number\n",
    "\n",
    "window = Window.partitionBy(df_twitter['location']).orderBy(df_twitter['retweet_count'].desc())\n",
    "\n",
    "df_twitter.select(\"location\",\"id\",\"retweet_count\", row_number().over(window).alias('rank')).filter(col('rank') <= 3).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------+----+\n",
      "|location|                 id|retweet_count|rank|\n",
      "+--------+-------------------+-------------+----+\n",
      "|  Canada|1252335430323888128|         9997|   1|\n",
      "|  Canada|1252254877939531776|         9992|   2|\n",
      "|  Canada|1252252082825986051|         9987|   3|\n",
      "|   Chile|1252253612140490759|         9988|   1|\n",
      "|   Chile|1252334891951427585|         9984|   2|\n",
      "|   Chile|1252253710182481920|         9978|   3|\n",
      "|   China|1252335780707684352|         9998|   1|\n",
      "|   China|1252253596516843520|         9993|   2|\n",
      "|   China|1252255562525560832|         9984|   3|\n",
      "| Germany|1252334028092399622|         9999|   1|\n",
      "| Germany|1252330902325248000|         9997|   2|\n",
      "| Germany|1252252295510855682|         9990|   3|\n",
      "|   India|1252332114948874240|         9988|   1|\n",
      "|   India|1252252336921206787|         9976|   2|\n",
      "|   India|1252254519116746754|         9973|   3|\n",
      "|   Italy|1252252106750377996|         9994|   1|\n",
      "|   Italy|1252251206027816960|         9984|   2|\n",
      "|   Italy|1252330500670337024|         9971|   3|\n",
      "|  Mexico|1252253843145912320|         9998|   1|\n",
      "|  Mexico|1252255209776189442|         9994|   2|\n",
      "+--------+-------------------+-------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table.\n",
    "spark.sql(\"\"\"SELECT location, id, retweet_count, rank \n",
    "FROM (SELECT location, id, retweet_count,ROW_NUMBER() OVER (PARTITION BY location ORDER BY retweet_count DESC) AS rank FROM twitter) tmp \n",
    "WHERE rank <= 3 ORDER BY location, rank\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.9 Total number of tweets per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('USA', 1539),\n",
       " ('Pakistan', 1470),\n",
       " ('Mexico', 1409),\n",
       " ('Spain', 1464),\n",
       " ('Canada', 1441),\n",
       " ('Germany', 1426),\n",
       " ('India', 1480),\n",
       " ('China', 1457),\n",
       " ('UK', 1376),\n",
       " ('Chile', 1410)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD (3 points)\n",
    "country_tweet = rdd_twitter.map(lambda s : (s[6],1))\n",
    "country_tweet=country_tweet.reduceByKey(lambda a, b : a + b)\n",
    "country_tweet.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|location|count|\n",
      "+--------+-----+\n",
      "| Germany| 1426|\n",
      "|   India| 1480|\n",
      "|   China| 1457|\n",
      "|   Chile| 1410|\n",
      "|   Italy| 1422|\n",
      "|   Spain| 1464|\n",
      "|     USA| 1539|\n",
      "|  Mexico| 1409|\n",
      "|      UK| 1376|\n",
      "|  Canada| 1441|\n",
      "|Pakistan| 1470|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using DataFrame (2 points)\n",
    "df_twitter.groupBy(\"location\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|location|count(1)|\n",
      "+--------+--------+\n",
      "| Germany|    1426|\n",
      "|   India|    1480|\n",
      "|   China|    1457|\n",
      "|   Chile|    1410|\n",
      "|   Italy|    1422|\n",
      "|   Spain|    1464|\n",
      "|     USA|    1539|\n",
      "|  Mexico|    1409|\n",
      "|      UK|    1376|\n",
      "|  Canada|    1441|\n",
      "|Pakistan|    1470|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table. (1 point)\n",
    "spark.sql(\"SELECT location, COUNT(*) FROM twitter GROUP BY location \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 save the data such that you have seperate folder per country (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataFrame\n",
    "df_twitter.write.partitionBy(\"location\").format(\"json\").save(\"tweetsByLocation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Save the data as parquet files (1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataFrame\n",
    "df_twitter.write.save(\"tweets.parquet\", format=\"parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
